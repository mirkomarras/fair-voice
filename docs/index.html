<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Agency - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
       <link href="https://fonts.googleapis.com/css2?family=Abril+Fatface&family=Exo+2:wght@100;800&display=swap" rel="stylesheet">
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top"><h3 style="font-size:30px"> FairVoice </h3></a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">Menu<i class="fas fa-bars ml-1"></i></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">ABOUT</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#statistics">STATISTICS</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">DOWNLOAD</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">PUBLICATIONS</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">CONTACT</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div class="container">
              <!--  <div class="masthead-subheading">Welcome To Our Studio!</div> -->
                <div style="font-family: 'Exo 2';font-size:80px">FairVoice Toolbox </div>
              <!--  <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#services">Tell Me More</a> -->
            </div>
        </header>
        <!-- Services-->
        <section class="page-section" id="about">
            <div class="container">
                <div class="text-center">
                    <h2 style="font-size:40px">FairVoice Toolbox</h2>
                  </br></br>
                    <p class="text-muted">Speaker recognition has been actively studied over the years, and has recently undergone a revolution thanks to deep-learned acoustic representations that outperformed
                       hand-crafted features based on Gaussian mixture models~\cite{reynolds2000speaker}, joint factor analysis~\cite{dehak2011front}, or i-Vectors
                       Modern systems learn to extract extremely accurate acoustic feature representations from one of the layers of a properly trained deep neural network.
                       State-of-the-art modelling includes c-Vectors , x-Vectors , VGGVox-Vectors , and ResNet-Vectors,
                       among others.
                       Despite high overall accuracy, speaker recognition may be influenced by the inherent characteristics of the individuals, and suffer from demographic bias that causes
                       certain populations to experience higher error rates than others. This deficiency can put certain groups more at risk than others against impostors attacks.
                       While such a bias could be attributed to the lack of sufficiently diverse training data (e.g., VoxCeleb corpus),
                       it nevertheless brings into question the unfairness of speaker recognition, also going beyond gender (e.g., race, territory),
                       and its mitigation, when these systems are used by heterogeneous populations.</p>
                  </br></br>
                </div>
              </div>>
      </section>
      <section class="page-section" id="statistics">
        <div class="container">
        <div class="text-center">
            <h2 style="font-size:40px">Statistics</h2>
            </br>
            <p class="section-subheading text-muted">In here you can be found some statistics about the dataset.</p>
          </br></br>
          </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <h4 class="service-heading"><p style="font-family: 'Exo 2', sans-serif;font-size:40px; color:#c82a2a;"<b>1.046.078</b> </p></h4>
                        <h4 style="font-family: 'Exo 2'">Utterances</h4>
                        <p class="text-muted">The data we collected included individuals that span from different country and different languages (i.e., Chinese, French, German, English, and Kabyle)</p>
                    </div>
                    <div class="col text-center">
                        <h4 class="service-heading"><p style="font-family: 'Exo 2', sans-serif;font-size:40px; color:#c82a2a;"<b>12.057</b> </p></h4>
                        <h4 style="font-family: 'Exo 2'">Speakers</h4>
                        <p class="text-muted">Each speaker declared some sensitive attributes, i.e., his/her accent, age, and gender.</p>
                    </div>
        </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/gend.png" alt="" height="300" width="300" align="middle">
                        <h4  style="font-family: 'Exo 2'">Gender Statistics</h4>
                        <p class="text-muted">Speaker distribution across lenguage.</p>
                    </div>
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/lan.png" alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Language Statistics</h4>
                        <p class="text-muted">Speaker distribution across languages.</p>
                    </div>
        </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/age.png"  alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Age Statistics</h4>
                        <p class="text-muted">Age distribution across speakers.</p>
                    </div>
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/audio.png" alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Utterances per Speaker</h4>
                        <p class="text-muted">Utterance distribution across speakers..</p>
                    </div>
         </div>
        </div>
        </section>
        <!-- Portfolio Grid -->
        <section class="bg-light" id="portfolio">
          <div class="container">
              <div class="text-center">
                  <h2 style="font-size:40px">Download</h2>
                  </br>
                  <p class="section-subheading text-muted">In here you can find the code and the dataset used for the test, if you want download the dataset please compile the form at the following  <a href="https://docs.google.com/forms/d/1Et3VxKpG2xKwOF46uT5sZvnTmOMiXYhVkZUJRwL7aFA/prefill"<p>link</p></a>.</p>
              </div>
          </br></br></br>
          <!--  <h3 class="section-subheading text-muted">Vox1 and Vox2. Provide urls, face detections and tracks, audio files, cropped face images, speaker meta data.
           </h3> -->
        <div class="row">
         <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link" href="https://docs.google.com/forms/d/1Et3VxKpG2xKwOF46uT5sZvnTmOMiXYhVkZUJRwL7aFA/prefill">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/logos/db.png" alt="" height="100" width="150" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>FairVoice Dataset</h4>
             <p class="text-muted">FairVoice contains over 1.046.078 utterances for 12.057 Speaker.</p>
           </div>
         </div>
         <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link" href="https://docs.google.com/forms/d/1Et3VxKpG2xKwOF46uT5sZvnTmOMiXYhVkZUJRwL7aFA/prefill">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/logos/db.png" alt="" height="100" width="150" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>Models</h4>
             <p class="text-muted">Pre-trained models.</p>
           </div>
         </div>

           <!-- <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2"> -->
        <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link"  href="https://github.com/mirkomarras/fair-voice">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/GitHub-Logos/Octocat.png" alt="" height="200" width="200" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>Code</h4>
             <p class="text-muted">Code for evaluate fairness and bias by the state-of-the-art speaker verification models.</p>
           </div>
         </div>
     </div>
     <div class="container">
       <div class="row">
         <div class="col-lg-12 text-center">
           <h5 class="section-heading text-uppercase">License</h5>
          <p>
           The FairVoice dataset is available to download for commercial/research purposes under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License. </a> The copyright remains with the original owners. A complete version of the license can be found <a href="files/license.txt"> here. </a> </p>
           <p class="section-subheading text-muted">Please contact the authors below if you have any question regarding the dataset.</p>
         </div>
       </div>
     </div>
    </div>
   </section>

        <!-- About -->
 <section id="publications">
   <div class="container">
     <div class="row">
       <div class="col-lg-12 text-center">
         <h2 style="font-size:40px">Publications</h2>
         </br>
         <p class="section-subheading text-muted">Please cite the following if you make use of the dataset.</p>
          </br></br></br>
         <div class="ref"  style="color:#404040;font-size:20px">
           <div class="Paper">
            G. Fenu,
            H. Lafhouli,
            M. Marras
            <a class="portfolio-link" data-toggle="modal"  href="#portfolioModal1">
             <b>Exploring Algorithmic Fairness in Deep Speaker Verification. </b>
            </a> &nbsp;
             In proceeding in the  20th International Conference on Computational Science and its Applications,  2020.
            <a a class="portfolio-link" data-toggle="modal"  href="#portfolioModal1">info</a>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>

        <!-- Contact-->
        <section class="page-section" id="contact">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Contact us</h2>
                    </br>
                    <h3 class="section-subheading text-muted">For information and questions please contact:</h3>
                    <h3 class="section-subheading text-muted">123@gmail.com</h3>
                </div>

               </div>
        </section>
        <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-left">Copyright © FairVoice</div>
                    <div class="col-lg-4 my-3 my-lg-0">
                        <a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-twitter"></i></a><a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-facebook-f"></i></a><a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-linkedin-in"></i></a>
                    </div>
                    <div class="col-lg-4 text-lg-right">Design by<a href="#!"> BootStrap</a>, adapted by Hicham</div>
                </div>
            </div>
        </footer>
        <!-- Portfolio Modals--><!-- Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h3 class="text-uppercase">Exploring Algorithmic Fairness in Deep Speaker Verification.</h3>
                                    <p class="item-intro text-muted">Integrating voice commands into modern automated systems can support individuals to manage data (e.g., messages) or perform actions (e.g., payments), safely and easily.
                                       To accomplish voice-based tasks, automated systems are often required to match the speaker’s voice to a unique digital identity for verification. Despite high accuracy,
                                       it remains under-explored how speaker identity verification models could be influenced by the inherent characteristics of the individuals and unfortunately discriminate against a
                                       legally-protected class of users, identified by a common sensitive attribute. In this paper, we explore how state-of-the-art speaker verification models are susceptible
                                       to unfairness towards different demographic groups of users, according with their gender and age. To this end, we collected and capitalized on a voice dataset representing
                                       different demographic classes in order to assess how speaker verification models perform across users' groups. Experiments show that users belonging to certain demographic
                                      groups systematically experience higher error rates, highlighting the need of fairer speaker verification.</p>
                                    <p>Bibitex</p>
                                    <p class="text-muted">@Article{
                                      author       = "",
                                      title        = "Exploring Algorithmic Fairness in Deep Speaker Verification.",
                                      journal      = "",
                                      year         = "2020",
                                      publisher    = "",
                                    }
                                   </p>

                                    <button class="btn btn-primary" data-dismiss="modal" type="button"><i class="fas fa-times mr-1"></i>close</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
