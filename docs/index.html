<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Fairvoice Toolbox</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css2?family=Abril+Fatface&family=Exo+2:wght@100;800&display=swap" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Righteous&display=swap" rel="stylesheet">
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top"><h3 style="font-size:30px"> FairVoice </h3></a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">Menu<i class="fas fa-bars ml-1"></i></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">ABOUT</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#statistics">STATISTICS</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#portfolio">DOWNLOAD</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">PUBLICATIONS</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">CONTACT</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead">
            <div>
              <!--  <div class="masthead-subheading">Welcome To Our Studio!</div> -->
                <div style="font-family:'Righteous';font-size:80px; text-shadow: 2px 2px #ff0000">FairVoice Toolbox </div>
              <!--  <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="#services">Tell Me More</a> -->
            </div>
        </header>
        <!-- Services-->
        <section class="page-section" id="about">
            <div class="container">
                <div class="text-center">
                    <h2 style="font-size:40px">FairVoice Toolbox</h2>
                  </br></br>
                    <p class="text-muted">The human voice conveys unique characteristics of an individual, making voice biometrics a key technology for verifying identities in various industries. Despite the impressive progress of speaker recognition systems in terms of accuracy, a number of ethical and legal concerns has been raised, specifically relating to the fairness of such systems. Our work aims to explore the disparity in performance achieved by state-of-the-art deep speaker recognition systems, when different groups of individuals characterized by a common sensitive attribute (e.g., gender) are considered. In order to mitigate the unfairness we uncovered by means of an exploratory study, we investigate whether balancing the representation of the different groups of individuals in the training set can lead to a more equal treatment of these demographic groups. Experiments on two state-of-the-art neural architectures and a large-scale public dataset show that models trained with demographically-balanced training sets exhibit a fairer behavior on different groups, while still being accurate. Our study is expected to provide a solid basis for instilling beyond-accuracy objectives (e.g., fairness) in speaker recognition.</p>
                  </br></br>
                </div>
              </div>>
      </section>
      <section class="page-section" id="statistics">
        <div class="container">
        <div class="text-center">
            <h2 style="font-size:40px">Statistics</h2>
            </br>
            <p class="section-subheading text-muted">Here you can find some statistics about the dataset.</p>
          </br></br>
          </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <h4 class="service-heading"><p style="font-family: 'Exo 2', sans-serif;font-size:40px; color:#c82a2a;"><b>1.046.078</b> </p></h4>
                        <h4 style="font-family: 'Exo 2'">Utterances</h4>
                        <p class="text-muted">The data we collected includes individuals that span from different countries and different languages (i.e., Chinese, French, German, English, and Kabyle)</p>
                    </div>
                    <div class="col text-center">
                        <h4 class="service-heading"><p style="font-family: 'Exo 2', sans-serif;font-size:40px; color:#c82a2a;"><b>12.057</b> </p></h4>
                        <h4 style="font-family: 'Exo 2'">Speakers</h4>
                        <p class="text-muted">Each speaker declared some sensitive attributes, i.e., his/her accent, age, and gender.</p>
                    </div>
        </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/gend.png" alt="" height="300" width="300" align="middle">
                        <h4  style="font-family: 'Exo 2'">Gender Statistics</h4>
                        <p class="text-muted">Speaker distribution across lenguage.</p>
                    </div>
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/lan.png" alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Language Statistics</h4>
                        <p class="text-muted">Speaker distribution across languages.</p>
                    </div>
        </div>
        <div class="row text-center">
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/age.png"  alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Age Statistics</h4>
                        <p class="text-muted">Age distribution across speakers.</p>
                    </div>
                    <div class="col text-center">
                        <img class="img-fluid d-block mx-auto" src="assets/img/stats/audio.png" alt="" height="300" width="300" align="middle">
                        <h4 class="my-3">Utterances per Speaker</h4>
                        <p class="text-muted">Utterance distribution across speakers..</p>
                    </div>
         </div>
        </div>
        </section>
        <!-- Portfolio Grid -->
        <section class="bg-light" id="portfolio">
          <div class="container">
              <div class="text-center">
                  <h2 style="font-size:40px">Download</h2>
                  </br>
                  <p class="section-subheading text-muted">Here you can find the code and the dataset used for the test, if you want to download the dataset please compile the form at the following  <a href="https://docs.google.com/forms/d/1Et3VxKpG2xKwOF46uT5sZvnTmOMiXYhVkZUJRwL7aFA/prefill"><p>link</p></a>.</p>
              </div>
          </br></br></br>
          <!--  <h3 class="section-subheading text-muted">Vox1 and Vox2. Provide urls, face detections and tracks, audio files, cropped face images, speaker meta data.
           </h3> -->
        <div class="row">
         <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link" href="https://docs.google.com/forms/d/1Et3VxKpG2xKwOF46uT5sZvnTmOMiXYhVkZUJRwL7aFA/prefill">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/logos/db.png" alt="" height="100" width="150" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>FairVoice Dataset</h4>
             <p class="text-muted">FairVoice contains over 1.046.078 utterances for 12.057 Speaker.</p>
           </div>
         </div>
         <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link" href="https://drive.google.com/drive/folders/1vRk5J4Nf-ohGRSnguPRkgNMh4i8n0UWB">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/logos/models.png" alt="" height="100" width="150" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>Models</h4>
             <p class="text-muted">Pre-trained models.</p>
           </div>
         </div>

           <!-- <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2"> -->
        <div class="col-md-4 col-sm-6 portfolio-item">
           <a class="portfolio-link"  href="https://github.com/mirkomarras/fair-voice">
             <div class="portfolio-hover">
               <div class="portfolio-hover-content">
                 <i class="fa fa-plus fa-3x"></i>
               </div>
             </div>
             <img class="img-fluid d-block mx-auto" src="assets/img/GitHub-Logos/Octocat.png" alt="" height="200" width="200" align="middle">
           </a>
           <div class="portfolio-caption">
             <h4>Code</h4>
             <p class="text-muted">Code for evaluating fairness and bias by the state-of-the-art speaker verification models.</p>
           </div>
         </div>
     </div>
     <div class="container">
       <div class="row">
         <div class="col-lg-12 text-center">
           <h5 class="section-heading text-uppercase">License</h5>
          <p>
           The FairVoice dataset is available to download for commercial/research purposes under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License. </a> The copyright remains with the original owners. A complete version of the license can be found <a href="files/license.txt"> here. </a> </p>
           <p class="section-subheading text-muted">Please contact the authors below if you have any question regarding the dataset.</p>
         </div>
       </div>
     </div>
    </div>
   </section>

        <!-- About -->
 <section id="publications">
   <div class="container">
     <div class="row">
       <div class="col-lg-12 text-center">
         <h2 style="font-size:40px">Publications</h2>
         </br>
         <p class="section-subheading text-muted">Please cite the following if you make use of the dataset.</p>
          </br></br></br>
         <div class="ref"  style="color:#404040;font-size:20px">
           <div class="Paper">
                G. Fenu,
                H. Lafhouli,
                M. Marras
                <a class="portfolio-link" data-toggle="modal"  href="#portfolioModal1">
                 <b>Exploring Algorithmic Fairness in Deep Speaker Verification. </b>
                </a> &nbsp;
                 In proceeding in the  20th International Conference on Computational Science and its Applications,  2020.
                <a a class="portfolio-link" data-toggle="modal"  href="#portfolioModal1">info</a>
            </div>
             <br>
             <div class="Paper">
                 G. Fenu,
                 G. Medda,
                 G. Meloni,
                 M. Marras
                 <a class="portfolio-link" data-toggle="modal"  href="#portfolioModal2">
                     <b>Improving Fairness in Speaker Recognition. </b>
                 </a> &nbsp;
                 In proceeding in Symposium on Pattern Recognition and Applications,  2020.
                 <a a class="portfolio-link" data-toggle="modal"  href="#portfolioModal2">info</a>
             </div>
      </div>
    </div>
  </div>
  </div>
</section>

        <!-- Contact-->
        <section class="page-section" id="contact">
            <div class="container">
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Contact us</h2>
                    <h3 class="section-subheading text-muted">For information and questions please contact:</h3>
                    <h3 class="section-subheading text-muted">mirko.marras@unica.it</h3>
                    <h3 class="section-subheading text-muted">g.meloni31@studenti.unica.it</h3>
                    <h3 class="section-subheading text-muted">g.medda6@studenti.unica.it</h3>
                    <br><br>
                </div>

               </div>
        </section>
        <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-left">Copyright © FairVoice</div>
                    <div class="col-lg-4 my-3 my-lg-0">
<!--                        <a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-twitter"></i></a><a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-facebook-f"></i></a><a class="btn btn-dark btn-social mx-2" href="#!"><i class="fab fa-linkedin-in"></i></a>-->
                    </div>
                    <div class="col-lg-4 text-lg-right">Design by<a href="#!"> BootStrap</a>, adapted by Hicham</div>
                </div>
            </div>
        </footer>
        <!-- Portfolio Modals--><!-- Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h3 class="text-uppercase">Exploring Algorithmic Fairness in Deep Speaker Verification.</h3>
                                    <p class="item-intro text-muted">Integrating voice commands into modern automated systems can support individuals to manage data (e.g., messages) or perform actions (e.g., payments), safely and easily.
                                       To accomplish voice-based tasks, automated systems are often required to match the speaker’s voice to a unique digital identity for verification. Despite high accuracy,
                                       it remains under-explored how speaker identity verification models could be influenced by the inherent characteristics of the individuals and unfortunately discriminate against a
                                       legally-protected class of users, identified by a common sensitive attribute. In this paper, we explore how state-of-the-art speaker verification models are susceptible
                                       to unfairness towards different demographic groups of users, according with their gender and age. To this end, we collected and capitalized on a voice dataset representing
                                       different demographic classes in order to assess how speaker verification models perform across users' groups. Experiments show that users belonging to certain demographic
                                      groups systematically experience higher error rates, highlighting the need of fairer speaker verification.</p>
                                    <p>Bibitex</p>
                                    <p class="text-muted">@article{
                                        author={Fenu, G. and Lafhouli, H. and Marras, M.},
                                        title={{Exploring Algorithmic Fairness in Deep Speaker Verification}},
                                        journal="",
                                        year={2020}
                                        publisher={Proceedings of the 20th International Conference on Computational Science and its Applications (ICSSA2020). In Press. Springer}
                                        }
                                    </p>
                                    <button class="btn btn-primary" type="button"><a class="pdf_link" href="https://link.springer.com/chapter/10.1007/978-3-030-58811-3_6">PDF</a></button><br><br>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button"><i class="fas fa-times mr-1"></i>close</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h3 class="text-uppercase">Improving Fairness in Speaker Recognition.</h3>
                                    <p class="item-intro text-muted">The human voice conveys unique characteristics of an individual, making voice biometrics a key technology for verifying
                                        identities in various industries. Despite the impressive progress of speaker recognition systems in terms of accuracy, a number of ethical and legal
                                        concerns has been raised, specifically relating to the fairness of such systems. In this paper, we aim to explore the disparity in performance achieved
                                        by state-of-the-art deep speaker recognition systems, when different groups of individuals characterized by a common sensitive attribute (e.g., gender)
                                        are considered. In order to mitigate the unfairness we uncovered by means of an exploratory study, we investigate whether balancing the representation of
                                        the different groups of individuals in the training set can lead to a more equal treatment of these demographic groups. Experiments on two state-of-the-art
                                        neural architectures and a large-scale public dataset show that models trained with demographically-balanced training sets exhibit a fairer behavior on
                                        different groups, while still being accurate. Our study is expected to provide a solid basis for instilling beyond-accuracy objectives (e.g., fairness)
                                        in speaker recognition. </p>
                                    <p>Bibitex</p>
                                    <p class="text-muted">author={Fenu, G. and Medda, G. and Meloni, G. and Marras, M.},
                                        title={{Improving Fairness in Speaker Recognition}},
                                        journal="",
                                        year={2020}
                                        publisher={ Proceedings of the 2020 European Symposium on Software Engineering }
                                        }
                                    </p>
                                    <button class="btn btn-primary" type="button"><a class="pdf_link" href="https://arxiv.org/abs/2104.14067">PDF</a></button><br><br>
                                    <button class="btn btn-primary" data-dismiss="modal" type="button"><i class="fas fa-times mr-1"></i>close</button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Contact form JS-->
        <script src="assets/mail/jqBootstrapValidation.js"></script>
        <script src="assets/mail/contact_me.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
