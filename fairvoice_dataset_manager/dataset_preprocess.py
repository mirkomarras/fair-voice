import pandas as pd
import os
import shutil
import math
import re
import warnings
import ast
import itertools
import random
from random import shuffle
from collections import defaultdict
from enum import Enum, auto

ROUND_CORRECTOR = 1e-9


class IdCounter:
    """Class to manage the id that will be assigned to the new generated metadata files."""

    def __init__(self, id_start=0):
        self.id = id_start

    @staticmethod
    def get_id_counter_metadata(metadata, folder):
        """
        Each metadata generated by prepare_fair_voice is named "metadataX.csv" where X is a number. This function gets
        the number of the last metadata in folder in order to use the right if for the new generated files

        :param metadata: name of the main metadata (in our case metadata.csv is the original of the dataset)
        :param folder: directory where the metadatas are generated
        :return: a new IdCounter containing the id of the last generated metadata
        """
        metas = [os.path.splitext(x)[0] for x in os.listdir(folder) if x.startswith(os.path.splitext(metadata)[0])]
        metas = map(int, filter(None, map(lambda x: x.replace(os.path.splitext(metadata)[0], ''), metas)))
        return IdCounter(max(metas, default=0))

    def up(self):
        self.id += 1
        return self.id


class AutoName(Enum):
    """Enum parent class to override the method that assign the value to the enum entries."""

    def _generate_next_value_(name, start, count, last_values):
        return name.lower()


class Modes(AutoName):
    """Enum that represent the different modes of prepare_common_voice"""
    DISTINCT = auto()
    MERGE = auto()
    MERGE_FOREACH_LANG = auto()
    DISTINCT_MERGE = auto()
    DISTINCT_MERGE_FOREACH_LANG = auto()

    @staticmethod
    def check_mode(mode):
        if isinstance(mode, str):
            if mode not in [_mode.value for _mode in Modes.__members__.values()]:
                raise ValueError(
                    '"mode" can only have the values {}'.format([x.value for x in Modes.__members__.values()]))
        elif not isinstance(mode, Modes):
            raise ValueError(
                '"mode" can only have the values {}'.format([x.value for x in Modes.__members__.values()]))

    @staticmethod
    def is_mode_instance(o, *args):
        is_mode = False
        for mode in args:
            is_mode |= o == mode.value or o == mode

        return is_mode


class TestUsersLoader:
    """Class the loads the file containing a python array-like object with the users for the testing process."""
    def __init__(self, path):
        self.path = path
        if os.path.exists(self.path):
            with open(self.path, 'r') as test_users_file:
                self.test_users = ast.literal_eval(test_users_file.read())
        else:
            self.test_users = []

    def save(self):
        with open(self.path, 'w') as test_users_file:
            test_users_file.write(str(list(self.test_users)))


ages_vals = [
    "teens",
    "twenties",
    "thirties",
    "fourties",
    "fifties",
    "sixties",
    "seventies",
    "eighties",
    "nineties"
]

default = object()


def prepare_fair_voice(metadata="metadata.csv",
                       encoding="utf-8",
                       dir_metadata="/home/meddameloni/FairVoice/metadata",
                       young_cap=default,
                       min_sample=5,
                       group_by_lang=default,
                       lang_equality=False,
                       female_male_ratio=default,
                       young_old_ratio=default,
                       mode=Modes.MERGE,
                       tot_test_users=100):
    """
    This is the function of generation of metadatas. It takes some parameters and creates some metadatas in basis
    of passed parameters, one metadata for each parameter, so multiple values for each parameter results in a total of
    metadatas equals to the cartesian product of each value of each parameter. It can creates metadatas where users are
    distributed in terms of gender for 30% (0.3) of females and 70% (0.7) of males or in terms of age, or both, with or
    without the equalisation of users in terms of language. ##NOT FULLY IMPLEMENTED##

    :param metadata: the file with the metadata of all the users
    :param encoding: encoding of the csv, they are the same of the built-in "open" function
    :param dir_metadata: directory where the file of metadata is saved
    :param young_cap: array of caps. Each cap determines the age group from which a user is considered "old". If
    young_cap = ["thirties", "fourties"] two types of metadatas will be created, one where users with an age greater
    than or equals to thirties are considered old (the others young), and the other one where users with an age greater
    than or equals to fourties are considered old.
    :param min_sample: it filters all the users taking only the ones with almost the specified minimum of audio samples
    :param group_by_lang: array of the languages that need to be considered. If not specified all languages of the
    dataset are taken into consideration. If set to None the metadata is processed in basis of the other parameters
    :param lang_equality: if True it creates metadatas with a number of users equal among all the languages of
    group_by_lang (if group_by_lang is None this value is discarded).
    :param female_male_ratio: an array of couples of ratios with a sum of 1.0. It specifies the proportion of gender
    in the created metadatas. Default value is [(0.3, 0.7), (0.4, 0.6), (0.5, 0.5), (0.6, 0.4)]. One metadata is created
    for each value (or more depending on the number of values of the other parameters). First value is for females, the
    second for males.
    :param young_old_ratio: an array of couples of ratios with a sum of 1.0. It specifies the proportion of age
    in the created metadatas. Default value is [(0.4, 0.6), (0.5, 0.5), (0.6, 0.4)]. One metadata is created
    for each value (or more depending on the number of values of the other parameters). First values if for the young,
    the second for the old.
    :param mode:
        distinct: create a csv for each of the value in group_by_lang, female_male_ratio (young_old_ratio and young_cap)
        metadata_1.csv = female_male_ratio[0]
        ...
        metadata_n.csv = group_by_lang[0]
        metadata_n+1.csv = young_old_ratio[0] for each cap in young_cap
          example with young_old_ratio = [(0.3, 0.7)] and young_cap = ["fourties", "fifties"]
            metadata_1.csv = labels with (0.3, 0.7) young old ratio where "young" is each row with age < "fourties"
            metadata_2.csv = labels with (0.3, 0.7) young old ratio where "young" is each row with age < "fifties"

        merge: create a csv for each of the value of the group (female_male_ratio, (young_old_ratio and young_cap)) with
        the entries of all languages in group_by_lang
        metadata_1.csv = all langs in group_by_lang, (female_male_ratio[0], (young_old_ratio[0] and young_cap[0]))
        ...
        metadata_n.csv = all langs in group_by_lang, (female_male_ratio[0], (young_old_ratio[0] and young_cap[0]))
        metadata_n+1.csv = all langs in group_by_lang, (female_male_ratio[0], (young_old_ratio[0] and young_cap[1]))
        metadata_n+m.csv = all langs in group_by_lang, (female_male_ratio[3], (young_old_ratio[1] and young_cap[1]))

        merge_foreach_lang: same behaviour of merge, but taking into account one language at a time.
                      So if "merge" creates N csvs, "merge_foreach_lang" creates N*len(group_by_lang) csvs

        distinct_merge: shortcut to do both merge and distinct at once

        distinct_merge_foreach_lang: shortcut to do both merge_foreach_lang and distinct at once

    :param tot_test_users: This parameter needs an integer value, that is the number of users used for testing. This
    integer is used to load a file with a name in the form "test_users_LANGUAGE_100" where 100 is the value of
    tot_test_users. This file contains the users used for testing and it will be created by the function
    "split_dataset", one for each language. It can be useful when it is necessary to create different metadata with
    several types of distribution of the users, but maintaining the same users for testing and the users are distributed
    by this function without losing those users that are present in testing files.
    Right now is available only in distinct mode and it needs "lang_equality" to be True and "group_by_lang" not to be
    None.

    :return: the id of the first metadata generated by this function. It can be passed to "split_dataset", which takes
    all the metadatas present in the file "info_metadata_X_Y" (X is equal to the id returned by this function) and split
    them in train and test.
    """
    metadata_id = IdCounter.get_id_counter_metadata(metadata, dir_metadata)
    start_id = metadata_id.id

    csvs_info = {
        "name": [],
        "group by language": [],
        "female male ratio": [],
        "young old ratio": [],
        "young cap": [],
        "n_sample": [],
        "mode": []
    }

    if young_cap is default or not young_cap:
        young_cap = ["fourties"]

    if female_male_ratio is default:
        female_male_ratio = [(0.3, 0.7), (0.4, 0.6), (0.5, 0.5), (0.6, 0.4)]

    if young_old_ratio is default:
        young_old_ratio = [(0.4, 0.6), (0.5, 0.5), (0.6, 0.4)]

    Modes.check_mode(mode)

    labels = pd.read_csv(os.path.join(dir_metadata, metadata), sep=',', encoding=encoding)
    labels = labels.loc[labels["n_sample"] >= min_sample]

    languages = labels.groupby("language_l1")
    if group_by_lang is default:
        groups = [lang for lang in languages.groups]
    elif group_by_lang:
        groups = group_by_lang
        group_errors = [lang for lang in groups if lang not in languages.groups]
        if group_errors:
            raise ValueError('{} are not languages of the dataset', group_errors)
    else:
        groups = None

    if lang_equality and group_by_lang:
        min_lang_users = min([len(languages.get_group(lang)) for lang in groups])

    if Modes.is_mode_instance(mode, Modes.DISTINCT):
        # if lang_equality:
        #     warnings.warn("lang_equality is pointless in DISTINCT mode", RuntimeWarning)

        prepare_distinct(metadata=metadata,
                         dir_metadata=dir_metadata,
                         labels=labels,
                         csvs_info=csvs_info,
                         metadata_id=metadata_id,
                         groups=groups,
                         female_male_ratio=female_male_ratio,
                         young_old_ratio=young_old_ratio,
                         young_cap=young_cap,
                         mode=mode,
                         min_lang_users_test=(min_lang_users, tot_test_users) if "min_lang_users" in locals() else None)

    else:
        # at least one among "female_male_ratio", "young_old_ratio" needs to be an array of values (Nothing to merge)
        if not (female_male_ratio or young_old_ratio):
            raise ValueError('female_male_ratio or young_old_ratio must not be empty. Nothing to merge')

        if not groups and not (female_male_ratio and young_old_ratio):
            raise ValueError('groups = None is possible if both female_male_ratio and young_old_ratio are valid, '
                             'use DISTINCT mode instead')

        prepare_merge(metadata=metadata,
                      dir_metadata=dir_metadata,
                      labels=labels,
                      csvs_info=csvs_info,
                      metadata_id=metadata_id,
                      groups=groups,
                      female_male_ratio=female_male_ratio,
                      young_old_ratio=young_old_ratio,
                      young_cap=young_cap,
                      mode=mode,
                      min_lang_users=min_lang_users if "min_lang_users" in locals() else None)

        if Modes.is_mode_instance(mode, Modes.DISTINCT_MERGE, Modes.DISTINCT_MERGE_FOREACH_LANG):
            prepare_distinct(metadata=metadata,
                             dir_metadata=dir_metadata,
                             labels=labels,
                             csvs_info=csvs_info,
                             metadata_id=metadata_id,
                             groups=groups,
                             female_male_ratio=female_male_ratio,
                             young_old_ratio=young_old_ratio,
                             young_cap=young_cap,
                             mode=mode)

    save_info(csvs_info, dir_metadata, start_id, metadata_id.id)

    return start_id + 1


def prepare_distinct(metadata=None,
                     dir_metadata=None,
                     labels=None,
                     csvs_info=None,
                     metadata_id=None,
                     groups=None,
                     female_male_ratio=None,
                     young_old_ratio=None,
                     young_cap=None,
                     mode=None,
                     min_lang_users_test=None):
    """
    This function creates the metadatas in DISTINCT modes (DISTINCT, DISTINCT_MERGE, DISTINCT_MERGE_FOREACH_LANG). It is
    called by "prepare_fair_voice" and should be not used directly unless you are sure about what you are doing.
    :param metadata: see "prepare_fair_voice" function for this parameter
    :param dir_metadata: see "prepare_fair_voice" function for this parameter
    :param labels: DataFrame with the content of the metadata but filtered with min_sample
    :param csvs_info: dictionary used to create files with names of the form "info_metadata_X_Y.csv" with info about
    the generated metadata files
    :param metadata_id: the id of the last generated metadata file
    :param groups: array of the languages that will be used for the generation
    :param female_male_ratio: see "prepare_fair_voice" function for this parameter
    :param young_old_ratio: see "prepare_fair_voice" function for this parameter
    :param young_cap: see "prepare_fair_voice" function for this parameter
    :param mode: see "prepare_fair_voice" function for this parameter
    :param min_lang_users_test: it can be None or a couple of values. First value is the number of users necessary to
    have the same number of users among all languages, the second value is the value of the parameter "tot_test_users"
    of "prepare_fair_voice", that is the number of users used for testing

    :return:
    """
    local_mode = "{} ({})".format(mode.value, "distinct")

    if groups:
        for lang in groups:
            languages = labels.groupby("language_l1")
            lang_df = languages.get_group(lang)

            if min_lang_users_test:
                loaded_test_users = TestUsersLoader(
                    os.path.join(dir_metadata, 'test_users_{}_{}'.format(lang, min_lang_users_test[1]))
                )
                _, id_users = zip(*loaded_test_users.test_users)
                lang_df_1 = lang_df[lang_df["id_user"].isin(id_users)]
                lang_df_2 = lang_df[~lang_df["id_user"].isin(id_users)]
                lang_df_2 = lang_df_2.sort_values("n_sample", ascending=False).\
                    head(min_lang_users_test[0] - min_lang_users_test[1])
                lang_df = pd.concat([lang_df_1, lang_df_2])

            out_name = save_metadata(metadata, lang_df, dir_metadata, metadata_id)

            update_info(csvs_info,
                        out_name,
                        '{}->{}'.format(groups, lang),
                        None,
                        None,
                        None,
                        len(lang_df),
                        local_mode)

    if female_male_ratio:
        for fm_ratio in female_male_ratio:
            f_ratio = fm_ratio[0]
            m_ratio = fm_ratio[1]

            assert math.isclose(f_ratio + m_ratio, 1.0), "The sum of each tuple in female_male_ratio must be 1.0"

            genders = labels.groupby("gender")

            females = genders.get_group("female")
            males = genders.get_group("male")

            # tuple that associate a group and its new length
            excess = get_excess("male", "female", males, females, m_ratio, f_ratio, len(labels))

            if excess[0] == "male":
                males = males.sort_values("n_sample", ascending=False).head(excess[1])
            else:
                females = females.sort_values("n_sample", ascending=False).head(excess[1])

            fm_df = pd.concat([females, males])

            out_name = save_metadata(metadata, fm_df, dir_metadata, metadata_id)

            update_info(csvs_info,
                        out_name,
                        None,
                        fm_ratio,
                        None,
                        None,
                        len(fm_df),
                        local_mode)

    if young_old_ratio:
        for y_cap in young_cap:
            ages = {k: "young" if ages_vals.index(y_cap) > i else "old" for i, k in enumerate(ages_vals)}
            for yo_ratio in young_old_ratio:
                y_ratio = yo_ratio[0]
                o_ratio = yo_ratio[1]

                assert math.isclose(y_ratio + o_ratio, 1.0), "The sum of each tuple in young_old_ratio must be 1.0"

                group_ages = labels.set_index("age").groupby(ages)

                youngs = group_ages.get_group("young").reset_index()
                olds = group_ages.get_group("old").reset_index()

                excess = get_excess("old", "young", olds, youngs, o_ratio, y_ratio, len(labels))

                if excess[0] == "old":
                    olds = olds.sort_values("n_sample", ascending=False).head(excess[1])
                else:
                    youngs = youngs.sort_values("n_sample", ascending=False).head(excess[1])

                yo_df = pd.concat([youngs, olds])
                yo_df.insert(5, "age", yo_df.pop("age"))

                out_name = save_metadata(metadata, yo_df, dir_metadata, metadata_id)

                update_info(csvs_info,
                            out_name,
                            None,
                            None,
                            yo_ratio,
                            y_cap,
                            len(yo_df),
                            local_mode)


def prepare_merge(metadata=None,
                  dir_metadata=None,
                  labels=None,
                  csvs_info=None,
                  metadata_id=None,
                  groups=None,
                  female_male_ratio=None,
                  young_old_ratio=None,
                  young_cap=None,
                  mode=None,
                  min_lang_users=None):
    """
    This function creates the metadatas in MERGE modes
    (MERGE, MERGE_FOREACH_LANG, DISTINCT_MERGE, DISTINCT_MERGE_FOREACH_LANG)
    :param metadata: see "prepare_fair_voice" function for this parameter
    :param dir_metadata: see "prepare_fair_voice" function for this parameter
    :param labels: DataFrame with the content of the metadata but filtered with min_sample
    :param csvs_info: dictionary used to create files with names of the form "info_metadata_X_Y.csv" with info about
    the generated metadata files
    :param metadata_id: the id of the last generated metadata file
    :param groups: array of the languages that will be used for the generation
    :param female_male_ratio: see "prepare_fair_voice" function for this parameter
    :param young_old_ratio: see "prepare_fair_voice" function for this parameter
    :param young_cap: see "prepare_fair_voice" function for this parameter
    :param mode: see "prepare_fair_voice" function for this parameter
    :param min_lang_users: if not None it is the number of users necessary to have the same number of users among
    all languages.

    :return:
    """
    local_mode = "{} ({})".format(mode.value, "merge")
    tot_metadata = defaultdict(pd.DataFrame)

    if groups:
        languages = labels.groupby("language_l1")

        # used for language equality
        if min_lang_users is not None:
            out_metadata = []

            # languages = pd.concat([languages.get_group(lang).
            #                       sort_values("n_sample", ascending=False).head(min_lang_users) for lang in groups])
            # languages = languages.groupby("language_l1")

        for lang in groups:
            process_fm_yo_ratios(metadata,
                                 dir_metadata,
                                 csvs_info,
                                 metadata_id,
                                 female_male_ratio,
                                 young_old_ratio,
                                 young_cap,
                                 tot_metadata,
                                 languages,
                                 mode,
                                 local_mode,
                                 min_lang_users_data=out_metadata if min_lang_users else None,
                                 lang=lang)

        if min_lang_users is not None and \
                Modes.is_mode_instance(mode, Modes.MERGE_FOREACH_LANG, Modes.DISTINCT_MERGE_FOREACH_LANG):

            min_length = 1e10
            for _, data_groups in out_metadata:
                data_sum = sum([len(d_group) for d_group in data_groups])
                if data_sum < min_length:
                    min_length = data_sum

            n_data_groups = len(out_metadata[0][1])
            min_length = (min_length // n_data_groups) * n_data_groups  # if odd it becomes even
            min_for_group = min_length // n_data_groups

            for _lang, data_groups in out_metadata:
                data_minimized = list(map(lambda df: df.sort_values("n_sample", ascending=False).head(min_for_group),
                                          data_groups))

                final_metadata = pd.concat(data_minimized)
                final_metadata.insert(5, "age", final_metadata.pop("age"))

                out_name = save_metadata(metadata, final_metadata, dir_metadata, metadata_id)

                update_info(csvs_info,
                            out_name,
                            _lang,
                            (0.5, 0.5),
                            (0.5, 0.5),
                            young_cap[0],
                            len(final_metadata),
                            local_mode)

        if Modes.is_mode_instance(mode, Modes.MERGE, Modes.DISTINCT_MERGE):
            for key in tot_metadata:
                fm_ratio = re.search(r'(?<=fm).+?[)]', key)
                fm_ratio = fm_ratio[0] if fm_ratio else None

                yo_ratio = re.search(r'(?<=yo).+?[)]', key)
                yo_ratio = yo_ratio[0] if yo_ratio else None

                y_cap = re.search(r'(?<=[)] ).*', key)
                y_cap = y_cap[0] if y_cap else None

                meta_to_save = tot_metadata[key]

                if fm_ratio == '(0.5, 0.5)' and yo_ratio == '(0.5, 0.5)' and min_lang_users:
                    min_length = 1e10
                    for _, data_groups in out_metadata:
                        data_sum = sum([len(d_group) for d_group in data_groups])
                        if data_sum < min_length:
                            min_length = data_sum

                    n_data_groups = len(out_metadata[0][1])
                    min_length = (min_length // n_data_groups) * n_data_groups
                    min_for_group = min_length // n_data_groups

                    min_lang_meta = None
                    for _lang, data_groups in out_metadata:
                        data_minimized = list(
                            map(lambda df: df.sort_values("n_sample", ascending=False).head(min_for_group),
                                data_groups))

                        lang_meta = pd.concat(data_minimized)
                        lang_meta.insert(5, "age", lang_meta.pop("age"))
                        min_lang_meta = pd.concat([min_lang_meta, lang_meta])

                    meta_to_save = min_lang_meta
                out_name = save_metadata(metadata, meta_to_save, dir_metadata, metadata_id)

                update_info(csvs_info,
                            out_name,
                            groups,
                            fm_ratio,
                            yo_ratio,
                            y_cap,
                            len(tot_metadata[key]),
                            local_mode)

    elif young_old_ratio and female_male_ratio:
        process_fm_yo_ratios(metadata,
                             dir_metadata,
                             csvs_info,
                             metadata_id,
                             female_male_ratio,
                             young_old_ratio,
                             young_cap,
                             tot_metadata,
                             labels,
                             mode,
                             local_mode)

        if Modes.is_mode_instance(mode, Modes.MERGE, Modes.DISTINCT_MERGE):
            for key in tot_metadata:
                out_name = save_metadata(metadata, tot_metadata[key], dir_metadata, metadata_id)

                fm_ratio = re.search(r'(?<=fm).+?[)]', key)
                fm_ratio = fm_ratio[0] if fm_ratio else None

                yo_ratio = re.search(r'(?<=yo).+?[)]', key)
                yo_ratio = yo_ratio[0] if yo_ratio else None

                y_cap = re.search(r'(?<=[)] ).*', key)
                y_cap = y_cap[0] if y_cap else None

                update_info(csvs_info,
                            out_name,
                            None,
                            fm_ratio,
                            yo_ratio,
                            y_cap,
                            len(tot_metadata[key]),
                            local_mode)
    else:
        # this line should never be reachable
        raise ValueError('groups = None is possible if both female_male_ratio and young_old_ratio are valid, '
                         'use DISTINCT mode instead')


def process_fm_yo_ratios(metadata,
                         dir_metadata,
                         csvs_info,
                         metadata_id,
                         female_male_ratio,
                         young_old_ratio,
                         young_cap,
                         tot_metadata,
                         labels,
                         mode,
                         local_mode,
                         min_lang_users_data=None,
                         lang=None):
    """
    Function that handles the distribution of the users in the basis of the female_male_ratio and young_old_ratio

    :param metadata: see "prepare_fair_voice" function for this parameter
    :param dir_metadata: see "prepare_fair_voice" function for this parameter
    :param csvs_info: dictionary used to create files with names of the form "info_metadata_X_Y.csv" with info about
    the generated metadata files
    :param metadata_id: the id of the last generated metadata file
    :param groups: array of the languages that will be used for the generation
    :param female_male_ratio: see "prepare_fair_voice" function for this parameter
    :param young_old_ratio: see "prepare_fair_voice" function for this parameter
    :param young_cap: see "prepare_fair_voice" function for this parameter
    :param tot_metadata:
    :param labels: DataFrame containing the metadata to process
    :param mode: see "prepare_fair_voice" function for this parameter
    :param local_mode: string that determines if mode is "merge" or "distinct". It is used to give more information
    in info files to distinguish how metadatas are generated when shortcut modes like "DISTINCT_MERGE" are used
    :param min_lang_users_data: if not None it is an array that must contain a couple of values, the first is the
    language and the second is an array of the DataFrames of the groups created when processing the ratios
    (for instance the groups could be "female old", "female young", "male old", "male young"). If the mode is MERGE or
    DISTINCT_MERGE and lang_equality has been set to True in "prepare_fair_voice" the users need to balanced in terms of
    lang_equality because all the languages need to have the same number of users, but the distribution of female_male
    ratio and young_old ratio do not have to be lost, so "min_lang_users_data" is a data structure that holds the data
    of the groups and permits to equalise the users in terms of languages in the previous function, when the ratios for
    all the languages have already been processed.
    :param lang: the language of which the ratios need to be processed, only if "groups" is not empty

    :return:
    """
    if lang:
        rows = len(labels.get_group(lang))
    else:
        rows = len(labels)

    if female_male_ratio:
        for fm_ratio in female_male_ratio:
            f_ratio = fm_ratio[0]
            m_ratio = fm_ratio[1]

            assert math.isclose(f_ratio + m_ratio, 1.0), "The sum of each tuple in female_male_ratio must be 1.0"

            if lang:
                languages = labels
                genders = languages.get_group(lang).groupby("gender")
            else:
                genders = labels.groupby("gender")

            females = genders.get_group("female")
            males = genders.get_group("male")

            # tuple that associate a group and its new length
            excess = get_excess("male", "female", males, females, m_ratio, f_ratio, rows)

            if young_old_ratio:
                for y_cap in young_cap:
                    ages = {k: "young" if ages_vals.index(y_cap) > i else "old" for i, k in enumerate(ages_vals)}
                    for yo_ratio in young_old_ratio:
                        y_ratio = yo_ratio[0]
                        o_ratio = yo_ratio[1]

                        assert math.isclose(y_ratio + o_ratio, 1.0), \
                            "The sum of each tuple in young_old_ratio must be 1.0"

                        male_by_age = males.set_index("age").groupby(ages)
                        male_youngs = male_by_age.get_group("young").reset_index()
                        male_olds = male_by_age.get_group("old").reset_index()

                        female_by_age = females.set_index("age").groupby(ages)
                        female_youngs = female_by_age.get_group("young").reset_index()
                        female_olds = female_by_age.get_group("old").reset_index()

                        if excess[0] == "male":
                            tot_f = len(female_youngs) + len(female_olds)
                            if len(female_youngs) < round(tot_f * y_ratio - ROUND_CORRECTOR):
                                new_f_olds = round(len(female_youngs) / y_ratio - ROUND_CORRECTOR) - len(female_youngs)
                                female_olds = female_olds.sort_values("n_sample", ascending=False).head(new_f_olds)
                                tot_f = len(female_youngs) + new_f_olds
                            elif len(female_youngs) > round(tot_f * y_ratio - ROUND_CORRECTOR):
                                new_f_youngs = round(len(female_olds) / o_ratio - ROUND_CORRECTOR) - len(female_olds)
                                female_youngs = female_youngs.sort_values("n_sample", ascending=False).head(new_f_youngs)
                                tot_f = len(female_olds) + new_f_youngs

                            excess = (excess[0], round(tot_f / f_ratio - ROUND_CORRECTOR) - tot_f)

                            sample_size = min(len(male_youngs), round(excess[1] * y_ratio - ROUND_CORRECTOR))
                            male_youngs = male_youngs.sort_values("n_sample", ascending=False).head(sample_size)
                            sample_size = min(len(male_olds), round(excess[1] * o_ratio - ROUND_CORRECTOR))
                            male_olds = male_olds.sort_values("n_sample", ascending=False).head(sample_size)
                        else:
                            tot_m = len(male_youngs) + len(male_olds)
                            if len(male_youngs) < round(tot_m * y_ratio - ROUND_CORRECTOR):
                                new_m_olds = round(len(male_youngs) / y_ratio - ROUND_CORRECTOR) - len(male_youngs)
                                male_olds = male_olds.sort_values("n_sample", ascending=False).head(new_m_olds)
                                tot_m = len(male_youngs) + new_m_olds
                            elif len(male_youngs) > round(tot_m * y_ratio - ROUND_CORRECTOR):
                                new_m_youngs = round(len(male_olds) / o_ratio - ROUND_CORRECTOR) - len(male_olds)
                                male_youngs = male_youngs.sort_values("n_sample", ascending=False).head(new_m_youngs)
                                tot_m = len(male_olds) + new_m_youngs

                            excess = (excess[0], round(tot_m / m_ratio - ROUND_CORRECTOR) - tot_m)

                            sample_size = min(len(female_youngs), round(excess[1] * y_ratio - ROUND_CORRECTOR))
                            female_youngs = female_youngs.sort_values("n_sample", ascending=False).head(sample_size)
                            sample_size = min(len(female_olds), round(excess[1] * o_ratio - ROUND_CORRECTOR))
                            female_olds = female_olds.sort_values("n_sample", ascending=False).head(sample_size)

                        if min_lang_users_data is not None and yo_ratio == (0.5, 0.5) and fm_ratio == (0.5, 0.5):
                            min_lang_users_data.append((lang, [female_olds, female_youngs, male_olds, male_youngs]))

                        out_females = pd.concat([female_olds, female_youngs])
                        out_males = pd.concat([male_olds, male_youngs])

                        out_metadata = pd.concat([out_females, out_males])
                        out_metadata.insert(5, "age", out_metadata.pop("age"))
                        tot_metadata["fm" + str(fm_ratio) + "yo" + str(yo_ratio) + " " + y_cap] = pd.concat(
                            [tot_metadata["fm" + str(fm_ratio) + "yo" + str(yo_ratio) + " " + y_cap],
                             out_metadata]
                        )

                        if lang:
                            if Modes.is_mode_instance(mode, Modes.MERGE_FOREACH_LANG,
                                                      Modes.DISTINCT_MERGE_FOREACH_LANG) and min_lang_users_data is None:
                                out_name = save_metadata(metadata, out_metadata, dir_metadata, metadata_id)

                                update_info(csvs_info,
                                            out_name,
                                            lang,
                                            fm_ratio,
                                            yo_ratio,
                                            y_cap,
                                            len(out_metadata),
                                            local_mode)
                        else:
                            raise ValueError('MERGE_FOREACH_LANG and DISTINCT_MERGE_FOREACH_LANG cannot be used with '
                                             'group_by_lang = None')
            else:
                if excess[0] == "male":
                    males = males.sort_values("n_sample", ascending=False).head(excess[1])
                else:
                    females = females.sort_values("n_sample", ascending=False).head(excess[1])

                out_metadata = pd.concat([females, males])
                tot_metadata["fm" + str(fm_ratio)] = pd.concat([tot_metadata["fm" + str(fm_ratio)], out_metadata])

                if Modes.is_mode_instance(mode, Modes.MERGE_FOREACH_LANG,
                                          Modes.DISTINCT_MERGE_FOREACH_LANG):
                    out_name = save_metadata(metadata, out_metadata, dir_metadata, metadata_id)

                    update_info(csvs_info,
                                out_name,
                                lang,
                                fm_ratio,
                                None,
                                None,
                                len(out_metadata),
                                local_mode)
    elif young_old_ratio:
        for y_cap in young_cap:
            ages = {k: "young" if ages_vals.index(y_cap) > i else "old" for i, k in enumerate(ages_vals)}
            for yo_ratio in young_old_ratio:
                y_ratio = yo_ratio[0]
                o_ratio = yo_ratio[1]

                assert math.isclose(y_ratio + o_ratio, 1.0), \
                    "The sum of each tuple in young_old_ratio must be 1.0"

                # no need to check "if lang" because the else branch is executed only if female_male_ratio is None
                languages = labels
                group_ages = languages.get_group(lang).set_index("age").groupby(ages)

                youngs = group_ages.get_group("young").reset_index()
                olds = group_ages.get_group("old").reset_index()

                excess = get_excess("old", "young", olds, youngs, o_ratio, y_ratio, rows)

                if excess[0] == "old":
                    olds = olds.sort_values("n_sample", ascending=False).head(excess[1])
                else:
                    youngs = youngs.sort_values("n_sample", ascending=False).head(excess[1])

                out_metadata = pd.concat([youngs, olds])
                out_metadata.insert(5, "age", out_metadata.pop("age"))
                tot_metadata["yo" + str(yo_ratio) + " " + y_cap] = pd.concat(
                    [tot_metadata["yo" + str(yo_ratio) + " " + y_cap],
                     out_metadata]
                )

                if Modes.is_mode_instance(mode, Modes.MERGE_FOREACH_LANG,
                                          Modes.DISTINCT_MERGE_FOREACH_LANG):
                    out_name = save_metadata(metadata, out_metadata, dir_metadata, metadata_id)

                    update_info(csvs_info,
                                out_name,
                                lang,
                                None,
                                yo_ratio,
                                y_cap,
                                len(out_metadata),
                                local_mode)

    else:
        # this line should never be reachable
        raise ValueError('female_male_ratio or young_old_ratio must not be empty. Nothing to merge')


def get_excess(key1, key2, data1, data2, ratio1, ratio2, len_all_data):
    """
    :return: a tuple (group, len(new_group)) containing the group with more rows than the ratio and the number of rows
    to match the expected ratio
    """
    excess = (key1, len(data1))
    if len(data2) < round(len_all_data * ratio2 - ROUND_CORRECTOR):
        excess = (key1, round(len(data2) / ratio2 - ROUND_CORRECTOR) - len(data2))
    elif len(data2) > round(len_all_data * ratio2):
        excess = (key2, round(len(data1) / ratio1 - ROUND_CORRECTOR) - len(data1))

    return excess


def update_info(info, name, group_by_lang, female_male_ratio, young_old_ratio, young_cap, n_sample, mode_value):
    """Updates the dictionary "info" with the values passed as parameters."""
    info["name"].append(name)
    info["group by language"].append(group_by_lang)
    info["female male ratio"].append(female_male_ratio)
    info["young old ratio"].append(young_old_ratio)
    info["young cap"].append(young_cap)
    info["n_sample"].append(n_sample)
    info["mode"].append(mode_value)


def save_metadata(metadata, out_metadata, dir_metadata, metadata_id):
    """Saves the metadata contained in the DataFrame "out_metadata" and returns the output file name."""
    out_name = "{}{}.csv".format(os.path.splitext(metadata)[0], str(metadata_id.up()))
    out_metadata.to_csv(os.path.join(dir_metadata, out_name),
                        encoding="utf-8",
                        index=False)

    return out_name


def save_info(csvs_info, dir_metadata, start_id, end_id):
    """Saves the dictionary csvs_info that contains the info of each metadata generated by the last execution."""
    pd.DataFrame(data=csvs_info).to_csv(
        os.path.join(dir_metadata, "info_metadata_{}_{}.csv".format(start_id + 1, end_id)),
        encoding='utf-8',
        index=False
    )


def split_dataset(metadata="metadata.csv",
                  info_start_id=None,
                  encoding="utf-8",
                  dir_metadata="/home/meddameloni/FairVoice/metadata",
                  dir_dataset="/home/meddameloni/FairVoice",
                  test_percentage=0.2,
                  sample_equality=False,
                  sample_cap=default,
                  strong_equality=False,
                  sample_groups_equality=False,
                  tot_test_users=None,
                  test_equality=default,
                  test_per_lang=False,
                  load_test_users=False):
    """
    Function that takes the metadata files generated by "prepare_fair_voice" function and generated the csv files that
    will be used for testing and training.

    :param metadata: the file with the metadata of all the users
    :param info_start_id: the id of the first metadata from which the split need to start. If "info_start_id" = X then
    split_dataset will process all the files described in the file "info_metadata_X_Y.csv", so all the files unitl Y
    will be splitted
    :param encoding: encoding of the csv, they are the same of the built-in "open" function
    :param dir_metadata: directory where the file of metadata is saved
    :param dir_dataset: directory where the dataset is saved
    :param test_percentage: percentage of the dataset to be used for testing
    :param sample_equality: if True it can be used a cap to reduce the number of audio samples considered for each user.
    The cap is specified by the parameter "sample_cap".
    :param sample_cap: as a dictionary it can be used to specify the cap of audios of each user for each language
    dataset where the key is the language and the values is the cap, so the audio samples of each user will not be more
    than the specified value. As an integer it will be used as the cap for every language. This parameter is used only
    when "sample_equality" is True.
    :param strong_equality: for each group N users are taken for tests. N is chosen in this way:
                                        N * groups = len(dataset) * test_percentage
                            it can happen that some groups are represented by a number of users less than N.
                            In this situation:
                            - strong_equality = True ensure the equality of users in the groups for testing
                            changing the value of N = len(group with least number of users), but the number of users
                            for testing does not satisfy the test_percentage.
                            - strong_equality = False does not satisfy the equality of users among the groups, and
                            satisfies the test_percentage taking more users from the most represented group
    :param sample_groups_equality: if True the number of audio samples will be equalised among the groups (female old,
    female young, male old, male young)
    :param tot_test_users: if not None it is equal to the number of users used for testing
    :param test_equality: an array of 3 possible values ["random", "age", "gender"]. For each value a testing file
    will be generated with the type of balancing chosen. With "random" the couples of audio paths for test are chosen
    randomly, with "age" the couples are balanced by age and with "gender" the couples are balanced by gender.
    :param test_per_lang: if True the audio paths couples used for testing will be separated in multiple files depending
    on the language of the users, so each testing file will have couples among users of the same language
    :param load_test_users: if True the users used for testing are loaded from the files or the users chosen for testing
    will be saved at the end of the function if "tot_test_users" is None

    :return:
    """
    if test_equality is default:
        test_equality = ["random"]

    if sample_cap is default:
        sample_cap = 100

    csvs = []
    last_info_name = ""
    if info_start_id and isinstance(metadata, str):
        last_info = [file for file in os.listdir(dir_metadata)
                     if file.startswith("info_metadata_{}_".format(info_start_id))][0]
        last_info_name = last_info
        info_end_id = int(os.path.splitext(last_info)[0].split('_')[-1])

        last_info = pd.read_csv(os.path.join(dir_metadata, last_info), sep=',', encoding=encoding)

        for file in os.listdir(dir_metadata):
            meta_id = re.search(r'(?<={})\d+'.format(os.path.splitext(metadata)[0]), file)
            if meta_id:
                if info_start_id <= int(meta_id[0]) <= info_end_id:
                    csvs.append(file)
    elif isinstance(metadata, list):
        csvs = metadata
        meta_id = re.search(r'(?<=.)\d+', csvs[0])
        for file in os.listdir(dir_metadata):
            if file.startswith("info_metadata_"):
                info_start_id, info_end_id = map(int, os.path.splitext(file)[0].split('_')[2:])
                if meta_id:
                    if info_start_id <= int(meta_id[0]) <= info_end_id:
                        last_info_name = file
                        last_info = pd.read_csv(os.path.join(dir_metadata, file), sep=',', encoding=encoding)
                        break
                else:
                    raise ValueError("bad format of {}".format(csvs[0]))
    else:
        raise ValueError("info_start_id expects metadata as str, or metadata should be a list of files")

    if not os.path.exists(os.path.join(dir_metadata, 'train')):
        os.mkdir(os.path.join(dir_metadata, 'train'))
    if not os.path.exists(os.path.join(dir_metadata, 'test')):
        os.mkdir(os.path.join(dir_metadata, 'test'))

    if not os.path.exists(os.path.join(dir_metadata, 'train', "{}_{}".format(info_start_id, info_end_id))):
        os.mkdir(os.path.join(dir_metadata, 'train', "{}_{}".format(info_start_id, info_end_id)))
    else:
        shutil.rmtree(os.path.join(dir_metadata, 'train', "{}_{}".format(info_start_id, info_end_id)))
        os.mkdir(os.path.join(dir_metadata, 'train', "{}_{}".format(info_start_id, info_end_id)))
    if not os.path.exists(os.path.join(dir_metadata, 'test', "{}_{}".format(info_start_id, info_end_id))):
        os.mkdir(os.path.join(dir_metadata, 'test', "{}_{}".format(info_start_id, info_end_id)))
    else:
        shutil.rmtree(os.path.join(dir_metadata, 'test', "{}_{}".format(info_start_id, info_end_id)))
        os.mkdir(os.path.join(dir_metadata, 'test', "{}_{}".format(info_start_id, info_end_id)))

    stats = {
        "filename": [],
        "train users": [],
        "train user samples": [],
        "train % F-M": [],
        "train % Y-O": [],
        "train languages": [],
        "test users": [],
        "test user samples": [],
        "comments": []
    }

    for meta_csv in csvs:
        stats["filename"].append(meta_csv)
        stats["comments"].append('test_percentage = {}\tsample_equality = {}\tsample_cap = {}\tstrong_equality = {}\t'
                                 'sample_groups_equality = {}\t tot_test_users = {}\t'.format(test_percentage,
                                                                                              sample_equality,
                                                                                              sample_cap,
                                                                                              strong_equality,
                                                                                              sample_groups_equality,
                                                                                              tot_test_users))
        train_users = []
        test_users = []
        labels = pd.read_csv(os.path.join(dir_metadata, meta_csv), sep=',', encoding=encoding)

        languages = labels.groupby("language_l1")

        csv_info = last_info[last_info["name"] == meta_csv]
        info_langs = csv_info["group by language"].to_numpy()
        info_genders = csv_info["female male ratio"].to_numpy()
        info_age = csv_info["young old ratio"].to_numpy()
        y_cap = csv_info["young cap"].to_numpy()[0]
        info_mode = csv_info["mode"].to_numpy()[0]

        if not isinstance(y_cap, float):
            ages = {k: "young" if ages_vals.index(y_cap) > i else "old" for i, k in enumerate(ages_vals)}

        if not isinstance(info_langs[0], float):
            local_mode = re.search(r'(?<=[(]).*(?=[)])', info_mode)[0]
            if local_mode == 'merge':
                if '[' in info_langs[0]:
                    lang_data = ast.literal_eval(info_langs[0])
                else:
                    lang_data = [info_langs[0]]
            else:
                lang_data = [info_langs[0].split('->')[1]]

            stats["train languages"].append(lang_data)

            for lang in lang_data:
                lang_df = languages.get_group(lang)
                train_users, test_users, valid = process_split_fm_yo_ratios(lang_df,
                                                                            info_genders,
                                                                            info_age,
                                                                            ages if "ages" in locals() else None,
                                                                            train_users,
                                                                            test_users,
                                                                            test_percentage,
                                                                            strong_equality,
                                                                            tot_test_users,
                                                                            load_test_users=load_test_users,
                                                                            lang=lang,
                                                                            dir_metadata=dir_metadata)
                # distinct case
                if not valid:
                    for _lang in lang_data:
                        tr_u, te_u = get_train_test(languages.get_group(_lang),
                                                    test_percentage=test_percentage,
                                                    strong_equality=strong_equality,
                                                    tot_test_users=tot_test_users,
                                                    load_test_users=load_test_users,
                                                    dir_metadata=dir_metadata,
                                                    lang=_lang)
                        train_users = train_users + tr_u
                        test_users = test_users + te_u
                    break
        else:
            stats["train languages"].append('N/A')
            train_users, test_users, _ = process_split_fm_yo_ratios(labels,
                                                                    info_genders,
                                                                    info_age,
                                                                    ages if "ages" in locals() else None,
                                                                    train_users,
                                                                    test_users,
                                                                    test_percentage,
                                                                    strong_equality,
                                                                    tot_test_users)

        data = {'audio': [], 'label': []}
        train_id = 0

        young_cap = None
        if 'y_cap' in locals():
            if not isinstance(y_cap, float):
                young_cap = y_cap

        meta_id = re.search(r'(?<=.)\d+', meta_csv)
        meta_id = int(meta_id[0])

        stats["train users"].append(len(train_users))

        train_df = pd.DataFrame()
        for t_lang, t_id in train_users:
            train_df = pd.concat([train_df, labels[(labels["language_l1"] == t_lang) & (labels["id_user"] == t_id)]])

        if not isinstance(info_genders[0], float):
            train_df_gender = train_df.groupby("gender")
            if len(train_df_gender.groups) == 2:
                stats["train % F-M"].append((round(len(train_df_gender.get_group("female"))/len(train_df), 2),
                                             round(len(train_df_gender.get_group("male"))/len(train_df), 2)))
            elif "female" in train_df_gender.groups:
                stats["train % F-M"].append((round(len(train_df_gender.get_group("female")) / len(train_df), 2), "N/A"))
            else:
                stats["train % F-M"].append(("N/A", round(len(train_df_gender.get_group("male")) / len(train_df), 2)))
        else:
            stats["train % F-M"].append("N/A")

        if young_cap:
            train_df_age = train_df.set_index("age").groupby(ages)
            if len(train_df_age.groups) == 2:
                stats["train % Y-O"].append((round(len(train_df_age.get_group("young")) / len(train_df), 2),
                                             round(len(train_df_age.get_group("old")) / len(train_df), 2)))
            elif "young" in train_df_age.groups:
                stats["train % Y-O"].append((round(len(train_df_age.get_group("young")) / len(train_df), 2), "N/A"))
            else:
                stats["train % Y-O"].append(("N/A", round(len(train_df_age.get_group("old")) / len(train_df), 2)))
        else:
            stats["train % Y-O"].append("N/A")

        tot_audios = 0
        for user in train_users:
            tot_audios += add_user_audios(data, user, labels, sample_cap, sample_equality, dir_dataset,
                                          extra_data=train_id)
            train_id += 1
        stats["train user samples"].append(tot_audios)

        meta_mode = re.search(r'.*(?= [(])', info_mode)[0]

        if not isinstance(info_langs[0], float):
            train_df.to_csv(
                os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                             "{}_metadata-{}-train.csv".format(meta_id, info_langs[0])),
                encoding='utf-8',
                index=False
            )

            pd.DataFrame(data=data).to_csv(
                os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                             "{}_{}-train.csv".format(meta_id, info_langs[0])),
                encoding='utf-8',
                index=False
            )

            if sample_groups_equality:
                eq_train = equalize_train_group_samples(os.path.join(dir_metadata, "train",
                                                                     "{}_{}".format(info_start_id, info_end_id),
                                                                     "{}_{}-train.csv".format(meta_id, info_langs[0])),
                                                        metadata=train_df,
                                                        young_cap=young_cap)

                eq_train.to_csv(
                    os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                                 "{}_{}-train.csv".format(meta_id, info_langs[0])),
                    encoding='utf-8',
                    index=False
                )

                train_lables = pd.read_csv(
                    os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                                 "{}_{}-train.csv".format(meta_id, info_langs[0])),
                    sep=',',
                    encoding='utf-8'
                )

                grouped_train_labels = train_lables.groupby("label")
                for gr_train in grouped_train_labels.groups:
                    group_train = grouped_train_labels.get_group(gr_train)
                    lang_train, id_user = os.path.split(os.path.split(group_train["audio"].to_numpy()[0])[0])
                    train_df.loc[(train_df["language_l1"] == lang_train) & (train_df["id_user"] == id_user),
                                 ["n_sample"]] = len(group_train)

                train_df.to_csv(
                    os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                                 "{}_metadata-{}-train.csv".format(meta_id, info_langs[0])),
                    encoding='utf-8',
                    index=False
                )

        else:
            pd.DataFrame(data=data).to_csv(
                os.path.join(dir_metadata, "train", "{}_{}".format(info_start_id, info_end_id),
                             "{}_train.csv".format(meta_id)),
                encoding='utf-8',
                index=False
            )

        stats["test users"].append(len(test_users))
        test_user_samples = []

        for idx_t_e, t_e in enumerate(test_equality):
            if test_per_lang:
                per_lang_list = languages.groups
            else:
                per_lang_list = [None]
            for lang in per_lang_list:
                _test_users = test_users
                data = {'audio_1': [], 'audio_2': [], 'age_1': [], 'age_2': [], 'gender_1': [], 'gender_2': [],
                        'label': []}
                if lang:
                    _test_users = [_user for _user in _test_users if _user[0] == lang]

                tot_audios = 0
                for user in _test_users:
                    age_data = None
                    if young_cap:
                        age_data = (ages, _test_users, t_e)
                    else:
                        age_data = (None, _test_users, t_e)
                    tot_audios += add_user_audios(data, user, labels, sample_cap, sample_equality, dir_dataset,
                                                  extra_data=age_data)
                out_test_sample_stat = '{}_{} {} {}'.format(idx_t_e + 1, t_e, lang, tot_audios) if lang \
                    else '{}_{} {}'.format(idx_t_e + 1, t_e, tot_audios)
                test_user_samples.append(out_test_sample_stat)

                out_test = "{}_{}-test{}.csv".format(meta_id, lang, idx_t_e + 1) if lang \
                    else "{}_test{}.csv".format(meta_id, idx_t_e + 1)

                pd.DataFrame(data=data).to_csv(
                    os.path.join(dir_metadata, "test", "{}_{}".format(info_start_id, info_end_id), out_test),
                    encoding='utf-8',
                    index=False
                )
        stats["test user samples"].append(test_user_samples)

        test_df = pd.DataFrame()
        for t_lang, t_id in test_users:
            test_df = pd.concat([test_df, labels[(labels["language_l1"] == t_lang) & (labels["id_user"] == t_id)]])

        if not isinstance(info_langs[0], float):
            test_df.to_csv(
                os.path.join(dir_metadata, "test", "{}_{}".format(info_start_id, info_end_id),
                             "{}_metadata-{}-test.csv".format(meta_id, info_langs[0])),
                encoding='utf-8',
                index=False
            )

    pd.DataFrame(data=stats).to_csv(
        os.path.join(dir_metadata,
                     "train_test_stats_{}_{}.csv".format(info_start_id, info_end_id)
                     ),
        encoding='utf-8',
        index=False
    )


def process_split_fm_yo_ratios(df,
                               info_genders,
                               info_age,
                               ages,
                               train_users,
                               test_users,
                               test_percentage,
                               strong_equality,
                               tot_test_users,
                               load_test_users=False,
                               lang=None,
                               dir_metadata=None):
    """
    It takes a dataframe containing the rows of the current metadata, then it divide the metadata in the possible groups
    depending on the values of the parameters of "info_genders" and "info_age" which attest if age ratios or gender
    ratios have been used to generate the metadata files. Once the groups have been formed the function "get_train_test"
    is used to divide the users of each group in testing and training users.

    :param df: Pandas DataFrame containing the metadata of the users
    :param info_genders: array containing the female male ratio in the metadata. If not used Pandas parses it as a "nan"
    :param info_age: array containing the young old ratio in the metadata. If not used Pandas parses it as a "nan"
    :param ages: dictionary that associates each age group, e.g. "twenties", "fourties" to young group or old group
    :param train_users: array that will contain the users for training
    :param test_users: array that will containg users for testing
    :param test_percentage: see "split_dataset" function for this parameter
    :param strong_equality: see "split_dataset" function for this parameter
    :param tot_test_users: see "split_dataset" function for this parameter
    :param load_test_users: see "split_dataset" function for this parameter
    :param lang: current language of the considered users
    :param dir_metadata: see "split_dataset" function for this parameter

    :return: updated array of users for training and users for testing and a boolena which will be false only if age
    and gender data are not available.
    """
    if not isinstance(info_genders[0], float):
        genders = df.groupby("gender")

        males = genders.get_group("male")
        females = genders.get_group("female")

        if not isinstance(info_age[0], float):
            male_by_age = males.set_index("age").groupby(ages)
            male_youngs = male_by_age.get_group("young").reset_index()
            male_olds = male_by_age.get_group("old").reset_index()

            female_by_age = females.set_index("age").groupby(ages)
            female_youngs = female_by_age.get_group("young").reset_index()
            female_olds = female_by_age.get_group("old").reset_index()

            tr_u, te_u = get_train_test(male_youngs, male_olds, female_youngs, female_olds,
                                        test_percentage=test_percentage,
                                        strong_equality=strong_equality,
                                        tot_test_users=tot_test_users,
                                        dir_metadata=dir_metadata,
                                        load_test_users=load_test_users,
                                        lang=lang)
            _train_users = train_users + tr_u
            _test_users = test_users + te_u
            return _train_users, _test_users, True
        else:
            tr_u, te_u = get_train_test(females, males,
                                        test_percentage=test_percentage,
                                        strong_equality=strong_equality,
                                        tot_test_users=tot_test_users,
                                        dir_metadata=dir_metadata,
                                        load_test_users=load_test_users,
                                        lang=lang)
            _train_users = train_users + tr_u
            _test_users = test_users + te_u
            return _train_users, _test_users, True

    elif not isinstance(info_age[0], float):
        df_by_age = df.set_index("age").groupby(ages)

        youngs = df_by_age.get_group("young").reset_index()
        olds = df_by_age.get_group("old").reset_index()

        tr_u, te_u = get_train_test(youngs, olds,
                                    test_percentage=test_percentage,
                                    strong_equality=strong_equality,
                                    tot_test_users=tot_test_users,
                                    dir_metadata=dir_metadata,
                                    load_test_users=load_test_users,
                                    lang=lang)
        _train_users = train_users + tr_u
        _test_users = test_users + te_u
        return _train_users, _test_users, True
    else:
        return train_users, test_users, False


def get_train_test(*args,
                   test_percentage=None,
                   strong_equality=False,
                   tot_test_users=None,
                   dir_metadata=None,
                   load_test_users=False,
                   lang=None):
    """
    :param tot_test_users: if not None it is equal to the number of users used for testing
    :param args: takes as many arguments as the number of groups created (4 groups for male_youngs, male_olds,
                 female_youngs, female_olds)
    :param test_percentage: percentage of the dataset to be used for testing
    :param strong_equality: for each group N users are taken for tests. N is chosen in this way:
                                        N * groups = len(dataset) * test_percentage
                            it can happen that some groups are represented by a number of users less than N.
                            In this situation:
                            - strong_equality = True ensure the equality of users in the groups for testing
                            changing the value of N = len(group with least number of users), but the number of users
                            for testing does not satisfy the test_percentage.
                            - strong_equality = False does not satisfy the equality of users among the groups, and
                            satisfies the test_percentage taking more users from the most represented group
    :param dir_metadata: directory where the metadata file is saved (necessary to load the users used for testing)
    :param load_test_users: if True the users used for testing are loaded from the files or the users chosen for testing
    will be saved at the end of the function if "tot_test_users" is None
    :param lang: language actually processed (necessary to load the users used for testing of the right language)

    :return: two arrays of id_users, each id_user as str (train_users, test_users)
    """
    _train_users = []
    _test_users = []

    loaded_test_users = None
    if dir_metadata and load_test_users and lang:
        if tot_test_users:
            loaded_test_users = TestUsersLoader(
                os.path.join(dir_metadata, 'test_users_{}_{}'.format(lang, tot_test_users))
            )
        else:
            loaded_test_users = TestUsersLoader(
                os.path.join(dir_metadata, 'test_users_{}_{}'.format(lang, test_percentage))
            )

    groups_len = [len(df) for df in args]

    if not tot_test_users:
        tot_test_users = round(sum(groups_len) * test_percentage - ROUND_CORRECTOR)
    test_len = round(tot_test_users / len(args) - ROUND_CORRECTOR)

    min_df = min(groups_len)

    # not enough users to take "test_len" users from each group for testing
    if min_df < test_len:
        if strong_equality:
            test_len = min_df
        else:
            deficit = sum([test_len - df_len if df_len < test_len else 0 for df_len in groups_len])
            most_rep_df_len = max(groups_len) + deficit

    loaded_data = None
    if loaded_test_users:
        if len(loaded_test_users.test_users) > 0:
            loaded_data = loaded_test_users.test_users

    for df in args:
        lang_series = df["language_l1"].to_numpy(copy=True)
        id_series = df["id_user"].to_numpy(copy=True)
        _users = list(zip(lang_series, id_series))
        shuffle(_users)

        test_cut = test_len
        if "most_rep_df_len" in locals():
            if len(df) == most_rep_df_len:
                test_cut = most_rep_df_len

        users_for_testing = _users[:test_cut]
        users_for_training = _users[test_cut:]

        if loaded_data:
            users_for_testing = [_u for _u in _users if _u in loaded_data]
            users_for_training = [_u for _u in _users if _u not in loaded_data]
        elif loaded_test_users:
            loaded_test_users.test_users = loaded_test_users.test_users + users_for_testing

        _test_users = _test_users + users_for_testing
        _train_users = _train_users + users_for_training

    if loaded_test_users:
        loaded_test_users.save()

    return _train_users, _test_users


def add_user_audios(data, user, labels, sample_cap, sample_equality, dir_dataset, extra_data=None):
    """
    Function that add to the parameter "data" the rows of the csv files for training and testing, so its principal task
    is to add the paths of the file audios to the csv. The parameter "extra_data" contains different values depending on
    the fact that the files need to be added to a testing file or a training file.

    :param data: data structure that holds the data to be saved on the training and testing files
    :param user: couple of (lang, id_user) that represent the user whose audio samples need to be added to the training
    or testing files
    :param labels: DataFrame of the metadata of all the users
    :param sample_cap: see "split_dataset" function for this parameter
    :param sample_equality: see "split_dataset" function for this parameter
    :param dir_dataset: see "split_dataset" function for this parameter
    :param extra_data: if the audios to add are for training "extra_data" is an integer reprsenting the id of the user
    that will be used in the training phaes, whereas if the audios to add are for testing "extra_data" is a triple,
    where the first value is "ages" a dictionary that associates group ages ("twenties", "fourties") to "old" or "young"
    the second value is the array containing the users that will be used for testing, it is useful to generate the
    different type of equality in testing files, the third value is the array that should contain the types of equality
    between the users that make up of the audio paths couples inside the testing file (corresponds to the
    "split_dataset" function parameter "test_equality")

    :return: the total of unique audio samples inside the testing or training files
    """
    TEST_MAX_AUDIOS = 16

    audios = [file for file in os.listdir(os.path.join(dir_dataset, user[0], user[1]))
              if os.path.splitext(file)[1] == ".wav" or os.path.splitext(file)[1] == ".mp3"]

    if sample_equality:
        shuffle(audios)
        if isinstance(sample_cap, int):
            audios = audios[:sample_cap]
        else:
            if sample_cap[user[0]] != 'max':
                audios = audios[:sample_cap[user[0]]]
        # elif len(audios) < min_sample:
        #    raise ValueError("Metadata contains users with n_sample < min_sample chosen as argument.\n"
        #                     "min_sample = {}".format(min_sample))

    # training
    if isinstance(extra_data, int):
        train_id = extra_data

        data['audio'].extend([os.path.join(user[0], user[1], audio) for audio in audios])
        data['label'].extend([train_id] * len(audios))

        n_audios_stat = len(audios)

    # testing
    else:
        ages, test_users, test_eq = extra_data
        user_gender = labels[(labels["language_l1"] == user[0]) & (labels["id_user"] == user[1])]["gender"].to_numpy()[0]
        user_age = labels[(labels["language_l1"] == user[0]) & (labels["id_user"] == user[1])]["age"].to_numpy()[0]
        set_audios = set()

        if not sample_equality:
            shuffle(audios)

        audios = audios[:min(len(audios), TEST_MAX_AUDIOS)]

        # adding to the csv the triplets of audios of same user (label: 1)
        for audio1 in audios[:len(audios) // 2]:
            for audio2 in audios[len(audios) // 2:]:
                set_audios.add((user[1], audio1))
                set_audios.add((user[1], audio2))
                data['audio_1'].append(os.path.join(user[0], user[1], audio1))
                data['audio_2'].append(os.path.join(user[0], user[1], audio2))
                if ages:
                    data['age_1'].append(ages[user_age])
                else:
                    data['age_1'].append('')
                data['age_2'].append('')
                data['gender_1'].append(user_gender)
                data['gender_2'].append('')
                data['label'].append(1)

        index_user = test_users.index(user)

        only_random_possible = True

        if not isinstance(user_gender, float):
            if test_eq == "gender":
                only_random_possible = False
                not_found = True
                while not_found:
                    other_user = random.randint(0, len(test_users) - 1)
                    if labels[(labels["language_l1"] == test_users[other_user][0]) &
                              (labels["id_user"] == test_users[other_user][1])]["gender"].to_numpy()[0] == user_gender \
                            and (index_user != other_user):
                        not_found = False

        if ages:
            if test_eq == "age":
                only_random_possible = False
                not_found = True
                while not_found:
                    other_user = random.randint(0, len(test_users) - 1)
                    if ages[labels[(labels["language_l1"] == test_users[other_user][0]) &
                            (labels["id_user"] == test_users[other_user][1])]["age"].to_numpy()[0]] == ages[user_age] \
                            and (index_user != other_user):
                        not_found = False

        if test_eq == "random" or only_random_possible:
            other_user = index_user
            while other_user == index_user:
                other_user = random.randint(0, len(test_users) - 1)

        other_user = test_users[other_user]
        other_gender = labels[(labels["language_l1"] == other_user[0]) &
                              (labels["id_user"] == other_user[1])]["gender"].to_numpy()[0]
        other_age = labels[(labels["language_l1"] == other_user[0]) &
                           (labels["id_user"] == other_user[1])]["age"].to_numpy()[0]

        other_audios = [file for file in os.listdir(os.path.join(dir_dataset, other_user[0], other_user[1]))
                        if os.path.splitext(file)[1] == ".wav" or os.path.splitext(file)[1] == ".mp3"]
        shuffle(other_audios)
        other_audios = other_audios[:min(len(other_audios), TEST_MAX_AUDIOS)]

        # adding to the csv the triplets of audios of different users (label: 0)
        for audio1 in audios[:min(len(audios), TEST_MAX_AUDIOS // 2)]:
            for audio2 in other_audios[:min(len(other_audios), TEST_MAX_AUDIOS // 2)]:
                set_audios.add((user[1], audio1))
                set_audios.add((other_user[1], audio2))
                data['audio_1'].append(os.path.join(user[0], user[1], audio1))
                data['audio_2'].append(os.path.join(other_user[0], other_user[1], audio2))
                if ages:
                    data['age_1'].append(ages[user_age])
                    data['age_2'].append(ages[other_age])
                else:
                    data['age_1'].append('')
                    data['age_2'].append('')
                data['gender_1'].append(user_gender)
                data['gender_2'].append(other_gender)
                data['label'].append(0)

        n_audios_stat = len(set_audios)

    return n_audios_stat


def equalize_train_group_samples(file, metadata=None, young_cap="fourties"):
    """Equalise the number of audio samples among the different groups female old, female young, male old, male young"""
    train_data = pd.read_csv(file, sep=',', encoding='utf-8')
    if isinstance(metadata, str):
        meta = pd.read_csv(metadata, sep=',', encoding='utf-8')
    else:
        meta = metadata

    train_df = pd.DataFrame()
    train_labels = train_data.groupby("label")
    users = {}

    # generate metadata_train from train csv
    for gr in train_labels.groups:
        group_df = train_labels.get_group(gr)
        split_lang_id = os.path.split(os.path.split(group_df["audio"].to_numpy()[0])[0])
        users['_'.join(split_lang_id)] = (gr, len(group_df))
        train_df = pd.concat([train_df,
                              meta[(meta["language_l1"] == split_lang_id[0]) & (meta["id_user"] == split_lang_id[1])]])

    if young_cap:
        ages = {k: "young" if ages_vals.index(young_cap) > i else "old" for i, k in enumerate(ages_vals)}

    groups_labels = []
    tots = [0]*4
    tot_index = 0
    gender_df = train_df.groupby("gender")
    for gender in gender_df.groups:
        gender_group = gender_df.get_group(gender)
        if young_cap:
            age_df = gender_group.set_index("age").groupby(ages)
            for age in age_df.groups:
                age_group = age_df.get_group(age)
                gr_labels = []
                for row in age_group.itertuples():
                    user = users['{}_{}'.format(row.language_l1, row.id_user)]
                    tots[tot_index] += user[1]
                    gr_labels.append(user[0])
                groups_labels.append(gr_labels)
                tot_index += 1
        else:
            raise NotImplementedError()

    remove_factor = 0.4
    min_to_not_remove = 40
    min_tot = min(tots)
    for i in range(4):
        i_labels = iter(groups_labels[i])
        while tots[i] != min_tot:
            try:
                label = next(i_labels)
            except StopIteration:
                i_labels = iter(groups_labels[i])
                label = next(i_labels)
            if len(train_labels.get_group(label)) > min_to_not_remove:
                remove_n_rows = min((tots[i] - min_tot), round(len(train_labels.get_group(label)) * remove_factor))
            else:
                remove_n_rows = 0
            new_rows = len(train_labels.get_group(label)) - remove_n_rows
            train_data = pd.concat([train_labels.get_group(label).sample(new_rows),
                                    train_data[train_data["label"] != label]])
            train_labels = train_data.groupby("label")
            tots[i] -= remove_n_rows

    return train_data


if __name__ == "__main__":
    print()
